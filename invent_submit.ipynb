{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install catboost\n\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\n\nimport lightgbm as lgb\n\nimport xgboost as xgb\n\n#import optuna\n#from optuna import Trial\n\nfrom scipy.signal import periodogram\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import adfuller\n\nimport catboost\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom catboost import Pool, CatBoost\n\nimport sklearn\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, RidgeClassifier, Lasso, ElasticNet, Lars\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import StratifiedKFold, ShuffleSplit, train_test_split, KFold, TimeSeriesSplit, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, PowerTransformer, MaxAbsScaler\nfrom sklearn.impute import SimpleImputer, KNNImputer\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score, roc_curve, mean_squared_error, mean_squared_log_error\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\nimport datetime\nfrom datetime import datetime, timedelta, timezone\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nfrom statistics import mean\nimport math\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-17T14:42:06.446218Z","iopub.execute_input":"2022-09-17T14:42:06.446723Z","iopub.status.idle":"2022-09-17T14:42:17.768851Z","shell.execute_reply.started":"2022-09-17T14:42:06.446684Z","shell.execute_reply":"2022-09-17T14:42:17.767226Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"Requirement already satisfied: catboost in /opt/conda/lib/python3.7/site-packages (1.0.6)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.7/site-packages (from catboost) (5.10.0)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.7/site-packages (from catboost) (0.8.4)\nRequirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.7/site-packages (from catboost) (1.3.5)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from catboost) (1.15.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from catboost) (3.5.3)\nRequirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from catboost) (1.21.6)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from catboost) (1.7.3)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->catboost) (2022.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->catboost) (0.11.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->catboost) (3.0.9)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->catboost) (21.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->catboost) (1.4.3)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->catboost) (4.33.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->catboost) (9.1.1)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly->catboost) (8.0.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"holidays = pd.read_csv('../input/dac22-invent-analytics-project/holidays.csv')\nholidays['date'] = pd.to_datetime(holidays['date'])\nproduct = pd.read_csv('../input/dac22-invent-analytics-project/product.csv').rename(columns={'id': 'product_id'})\nsample = pd.read_csv('../input/dac22-invent-analytics-project/sample_submission.csv')\ntrain = pd.read_csv('../input/dac22-invent-analytics-project/train.csv')\ntest = pd.read_csv('../input/dac22-invent-analytics-project/test.csv')\ntrain['date'] = pd.to_datetime(train['date'])\ntest['date'] = pd.to_datetime(test['date'])\nall_data = pd.concat((train, test), axis=0)\nall_data = all_data.merge(product, on='product_id', how='left')\nall_data = all_data[all_data['store_count'] != 0]","metadata":{"execution":{"iopub.status.busy":"2022-09-17T18:09:24.334727Z","iopub.execute_input":"2022-09-17T18:09:24.335241Z","iopub.status.idle":"2022-09-17T18:09:26.027661Z","shell.execute_reply.started":"2022-09-17T18:09:24.335204Z","shell.execute_reply":"2022-09-17T18:09:26.026295Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"def get_time_till_next_season(x):\n    year = x.year\n    till_summer = (datetime(year, 6, 1) - x).days\n    till_fall = (datetime(year, 9, 1) - x).days\n    till_winter = (datetime(year, 12, 1) - x).days\n    till_spring = (datetime(year, 3, 1) - x).days\n    till_next_spring = (datetime(year+1, 3, 1) - x).days\n    till_all = [till_summer, till_fall, till_winter, till_spring, till_next_spring]\n    all_seasons = [x for x in till_all if x >= 0]\n    return min(all_seasons)\n    \nall_data['time_till_next_season'] = all_data['date'].apply(get_time_till_next_season)","metadata":{"execution":{"iopub.status.busy":"2022-09-17T18:09:29.753108Z","iopub.execute_input":"2022-09-17T18:09:29.753571Z","iopub.status.idle":"2022-09-17T18:09:53.819360Z","shell.execute_reply.started":"2022-09-17T18:09:29.753533Z","shell.execute_reply":"2022-09-17T18:09:53.817857Z"},"trusted":true},"execution_count":180,"outputs":[]},{"cell_type":"code","source":"all_data['is_main_promo'] = all_data['promotion_type'].fillna('').str.contains('Main Promo').astype(int)\nall_data['is_season_middle_promo'] = all_data['promotion_type'].fillna('').str.contains('Season Middle').astype(int)\n\nall_data['is_daily'] = (all_data['life_style'].fillna('').str.contains('Daily')).astype(int)\nall_data['is_dark'] = (all_data['life_style'].fillna('').str.contains('Dark')).astype(int)\n\nall_data['is_narrow'] = (all_data['form_type'].fillna('').str.contains('Narrow')).astype(int)\nall_data['is_normal'] = (all_data['form_type'].fillna('').str.contains('Normal')).astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-09-17T18:11:05.771928Z","iopub.execute_input":"2022-09-17T18:11:05.772325Z","iopub.status.idle":"2022-09-17T18:11:07.500064Z","shell.execute_reply.started":"2022-09-17T18:11:05.772295Z","shell.execute_reply":"2022-09-17T18:11:07.499122Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"code","source":"pro_cat_cols = [col for col in product.columns if col != 'id']\ntrain_cat_cols = ['product_id', 'season_type', 'promotion_type']\ncat_cols = [ 'category_1', 'category_2', 'category_3', 'color_type', 'life_style'\n           , 'fabric', 'weight_of_fabric', 'neck_style', 'form_type', 'sleeve_type', 'washing_style'\n           , 'fabric_type', 'season_type', 'promotion_type', 'season', 'all_category', 'holiday_name']\nto_drop_cols = ['id', 'date', 'sales_amount', 'product_id']\ntarget = 'sales_amount'","metadata":{"execution":{"iopub.status.busy":"2022-09-17T18:11:07.719959Z","iopub.execute_input":"2022-09-17T18:11:07.720641Z","iopub.status.idle":"2022-09-17T18:11:07.727295Z","shell.execute_reply.started":"2022-09-17T18:11:07.720605Z","shell.execute_reply":"2022-09-17T18:11:07.726061Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"code","source":"all_data['discounted_price'] = all_data['price'] - all_data['price']*all_data['discount']\nall_data['all_category'] = all_data['category_1'] + all_data['category_2'] + all_data['category_3']\n\ndef get_holiday(df):\n    dates = pd.DataFrame(df['date'].unique()).rename(columns={0: 'date'})\n    dates['is_holiday'] = 0\n    dates['holiday_name'] = ''\n    for i in tqdm(range(len(dates))):\n        for j in range(len(holidays)):\n            if (dates.at[i, 'date'] <= holidays.at[j, 'date']) and ((dates.at[i, 'date'] + timedelta(days=7)) > holidays.at[j, 'date']):\n                dates.at[i, 'is_holiday'] = 1\n                dates.at[i, 'holiday_name'] = holidays.at[j, 'holiday']\n    df = df.merge(dates, on='date', how='left')\n    return df\n                \nall_data = get_holiday(all_data)","metadata":{"execution":{"iopub.status.busy":"2022-09-17T18:11:13.236661Z","iopub.execute_input":"2022-09-17T18:11:13.237125Z","iopub.status.idle":"2022-09-17T18:11:17.565253Z","shell.execute_reply.started":"2022-09-17T18:11:13.237089Z","shell.execute_reply":"2022-09-17T18:11:17.564148Z"},"trusted":true},"execution_count":187,"outputs":[{"name":"stderr","text":"100%|██████████| 242/242 [00:03<00:00, 71.19it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"grouped = all_data.groupby(['all_category', 'date']).mean()['price'].reset_index().rename(columns={'price': 'mean_cat_price'})\nall_data = all_data.merge(grouped, on=['all_category', 'date'], how='left')\nall_data['price_mean_diff'] = all_data['price'] - all_data['mean_cat_price']","metadata":{"execution":{"iopub.status.busy":"2022-09-17T18:11:17.567303Z","iopub.execute_input":"2022-09-17T18:11:17.567700Z","iopub.status.idle":"2022-09-17T18:11:20.162273Z","shell.execute_reply.started":"2022-09-17T18:11:17.567667Z","shell.execute_reply":"2022-09-17T18:11:20.161182Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"code","source":"def get_season(x):\n    if (x >= 3) and (x < 6):\n        return 'spring'\n    if (x >= 6) and (x < 9):\n        return 'summer'\n    if (x >= 9) and (x < 12):\n        return 'autumn'\n    return 'winter'\n \ndef is_in_season(x):\n    if x.season_type == 'Autumn-Winter':\n        if (x.season == 'autumn') or (x.season == 'winter'):\n            return 1\n    if x.season_type == 'Summer-Spring':\n        if (x.season == 'summer') or (x.season == 'autumn'):\n            return 1\n    return 0\n\nall_data['month'] = all_data['date'].dt.month\nall_data['season'] = all_data['month'].apply(get_season)\nall_data['in_season'] = all_data.apply(is_in_season, axis=1)\n\nall_data['season_type+category_3'] = all_data['season_type'] + all_data['category_3']\nall_data['season+category_3'] = all_data['season'] + all_data['category_3']\n\nall_data['season_type+color_type'] = all_data['season_type'] + all_data['color_type']\nall_data['season+color_type'] = all_data['season'] + all_data['color_type']","metadata":{"execution":{"iopub.status.busy":"2022-09-17T18:11:25.797692Z","iopub.execute_input":"2022-09-17T18:11:25.798113Z","iopub.status.idle":"2022-09-17T18:11:48.617404Z","shell.execute_reply.started":"2022-09-17T18:11:25.798082Z","shell.execute_reply":"2022-09-17T18:11:48.616192Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"def how_many_weeks_past(df):\n    df['last_entry'] = df.groupby('product_id').shift(1)['date']\n    df['next_entry'] = df.groupby('product_id').shift(-1)['date']\n    df['weeks_since_last_entry'] = (df['date'] - df['last_entry']).dt.days / 7\n    df['weeks_to_next_entry'] = (df['next_entry'] - df['date']).dt.days / 7\n    df.drop(columns=['last_entry', 'next_entry'], inplace=True)\n    \nhow_many_weeks_past(all_data)","metadata":{"execution":{"iopub.status.busy":"2022-09-17T18:11:48.620157Z","iopub.execute_input":"2022-09-17T18:11:48.620672Z","iopub.status.idle":"2022-09-17T18:11:51.600572Z","shell.execute_reply.started":"2022-09-17T18:11:48.620626Z","shell.execute_reply":"2022-09-17T18:11:51.599285Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"all_data['last_is_here'] = (all_data['weeks_since_last_entry'] == 1)\nall_data['next_is_here'] = (all_data['weeks_to_next_entry'] == 1)\n\n#all_data['all_sold'] = (all_data['next_week_store_count'] > all_data['store_count']).astype(int)\n#all_data['none_sold'] = (all_data['store_count'] > all_data['next_week_store_count']).astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-09-17T18:11:51.602070Z","iopub.execute_input":"2022-09-17T18:11:51.602427Z","iopub.status.idle":"2022-09-17T18:11:51.612164Z","shell.execute_reply.started":"2022-09-17T18:11:51.602395Z","shell.execute_reply":"2022-09-17T18:11:51.610770Z"},"trusted":true},"execution_count":192,"outputs":[]},{"cell_type":"code","source":"def get_seri_no(df):\n    df['seri_no'] = np.nan\n    pro_u = df['product_id'].unique()\n    for u in tqdm(pro_u):\n        grouped = df[df['product_id'] == u].reset_index()\n        s = 0\n        for i in range(len(grouped)):\n            idx = grouped.iat[i, 0]\n            if(grouped.iat[i, -3] == 1):\n                df.at[idx, 'seri_no'] = s\n            else:\n                s += 1\n                df.at[idx, 'seri_no'] = s\n                \nget_seri_no(all_data)\nall_data = all_data.merge(all_data.groupby('product_id').count()['id'].reset_index().rename(columns={'id': 'product_count'}), on='product_id', how='left')","metadata":{"execution":{"iopub.status.busy":"2022-09-17T18:11:51.615422Z","iopub.execute_input":"2022-09-17T18:11:51.615915Z","iopub.status.idle":"2022-09-17T18:12:52.743350Z","shell.execute_reply.started":"2022-09-17T18:11:51.615859Z","shell.execute_reply":"2022-09-17T18:12:52.741866Z"},"trusted":true},"execution_count":193,"outputs":[{"name":"stderr","text":"100%|██████████| 7876/7876 [00:57<00:00, 136.92it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_min_max_diff(df, cols):\n    for col in cols:\n        \n        df = df.merge(df.groupby('product_id').max()[col].reset_index().rename(columns={col: 'max_'+col}), on='product_id', how='left')\n        df = df.merge(df.groupby('product_id').min()[col].reset_index().rename(columns={col: 'min_'+col}), on='product_id', how='left')\n        df = df.merge(df.groupby('product_id').mean()[col].reset_index().rename(columns={col: 'mean_'+col}), on='product_id', how='left')\n        #print(df)\n        df['min_'+col+'_diff'] = df[col] - df['min_'+col]\n        df['max_'+col+'_diff'] = df['max_'+col] - df[col]\n        df['mean_'+col+'_diff'] = df[col] - df['mean_'+col]\n        \n    return df\n\ndef get_seri_based(df, cols):\n    for col in cols:\n        \n        df = df.merge(df.groupby(['product_id', 'seri_no']).max()[col].reset_index().rename(columns={col: 'seri_max_'+col}), on=['product_id', 'seri_no'], how='left')\n        df = df.merge(df.groupby(['product_id', 'seri_no']).min()[col].reset_index().rename(columns={col: 'seri_min_'+col}), on=['product_id', 'seri_no'], how='left')\n        df = df.merge(df.groupby(['product_id', 'seri_no']).mean()[col].reset_index().rename(columns={col: 'seri_mean_'+col}), on=['product_id', 'seri_no'], how='left')\n        \n        df['seri_min_'+col+'_diff'] = df[col] - df['seri_min_'+col]\n        df['seri_max_'+col+'_diff'] = df['seri_max_'+col] - df[col]\n        df['seri_mean_'+col+'_diff'] = df[col] - df['seri_mean_'+col]\n        \n    return df\n\nall_data = get_min_max_diff(all_data, ['store_count', 'price'])\nall_data = get_seri_based(all_data, ['store_count', 'price'])","metadata":{"execution":{"iopub.status.busy":"2022-09-17T18:12:53.062154Z","iopub.execute_input":"2022-09-17T18:12:53.062578Z","iopub.status.idle":"2022-09-17T18:15:58.230772Z","shell.execute_reply.started":"2022-09-17T18:12:53.062543Z","shell.execute_reply":"2022-09-17T18:15:58.229435Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"code","source":"def shift_n_weeks(df, cols, shifts):\n    for col in cols:\n        for n in shifts:\n            df[col+'_shifted_'+str(n)] = df.groupby(['product_id', 'seri_no']).shift(n)[col]\n\nshift_n_weeks(all_data, ['store_count'], [-5, -4, -3, -2, -1, 1, 2, 3, 4, 5])\nshift_n_weeks(all_data, ['price'], [-1, 1])\n\nall_data['diff_last_week_store_count'] = all_data['store_count'] - all_data['store_count_shifted_1']\nall_data['diff_next_week_store_count'] = all_data['store_count_shifted_-1'] - all_data['store_count']\n\nall_data['diff_last_week_price'] = all_data['price'] - all_data['price_shifted_1']\nall_data['diff_next_week_price'] = all_data['price_shifted_-1'] - all_data['price']\n\nall_data['sudden_inc'] = (all_data['diff_next_week_store_count'] >= 50).astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-09-17T18:15:58.232587Z","iopub.execute_input":"2022-09-17T18:15:58.232911Z","iopub.status.idle":"2022-09-17T18:16:21.101773Z","shell.execute_reply.started":"2022-09-17T18:15:58.232883Z","shell.execute_reply":"2022-09-17T18:16:21.100556Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"def rmsle_lgbm(labels, preds):\n    score = np.sqrt(np.mean(np.power(np.log1p(labels) - np.log1p(np.clip(preds, 0, np.inf)), 2)))\n    return 'rmsle', score, False\n\nclass CatRMSLE(object):\n    # RMSLE for catboost\n    def get_final_error(self, error, weight):\n        return error / (weight + 1e-38)\n\n    def is_max_optimal(self):\n        return False\n\n    def evaluate(self, approxes, target, weight):\n        assert len(approxes) == 1\n        assert len(target) == len(approxes[0])\n\n        approx = approxes[0]\n\n        weight_sum = 1\n\n        score = np.sqrt(np.mean(np.power(np.log1p(target) - np.log1p(np.clip(approx, 0, np.inf)), 2)))\n\n        return score, weight_sum","metadata":{"execution":{"iopub.status.busy":"2022-09-17T14:46:05.009805Z","iopub.execute_input":"2022-09-17T14:46:05.010830Z","iopub.status.idle":"2022-09-17T14:46:05.023440Z","shell.execute_reply.started":"2022-09-17T14:46:05.010773Z","shell.execute_reply":"2022-09-17T14:46:05.022559Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"all_data['store_sales_diff'] = all_data['store_count'] - all_data['sales_amount']\nall_data['sales_store_div'] = all_data['sales_amount'] / all_data['store_count']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_cummean(df, to_groups, cols):\n    for col in cols:\n        for to_group in to_groups:\n            df[to_group+'_'+col+'_cummean'] = df.groupby(to_group)[col].apply(lambda x: x.shift().expanding().mean())\n    return df\n        \nall_data = get_cummean(all_data, to_groups=cat_cols, cols=['sales_amount', 'store_sales_diff', 'sales_store_div'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in cat_cols:\n    le = LabelEncoder()\n    all_data[col] = le.fit_transform(all_data[col])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The lgbm kfold\ntrain = all_data[all_data[target].notna()]\ntest = all_data[all_data[target].isna()]\nscores = []\nfold = 1\npreds = pd.Series(np.zeros(len(test)))\nkf = KFold(5, shuffle=True, random_state=27)\npreds = pd.Series(np.zeros(len(test)))\nfor train_ind, val_ind in kf.split(train):\n    tr = train.iloc[train_ind]\n    val = train.iloc[val_ind]\n    lgb_reg = lgb.LGBMRegressor(num_leaves=63, learning_rate=0.2, metric=[rmsle_lgbm, 'mae'],\n                             n_estimators=2000, objective='mae', first_metric_only='true', random_state=42)\n    lgb_reg.fit(tr.drop(columns=to_drop_cols), tr[target]\n               ,eval_set=(val.drop(columns=to_drop_cols), val[target])\n               ,eval_metric=rmsle_lgbm\n               ,early_stopping_rounds=200\n               ,verbose=100\n              ,categorical_feature=cat_cols\n                   )\n    print(lgb.plot_importance(lgb_reg, height=0.2, figsize=(12,8), importance_type='gain'))\n    preds += lgb_reg.predict(test.drop(columns=to_drop_cols))\n\npreds /= 5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.clip(preds, 0, np.inf)\n#preds = np.expm1(preds)\nsample['sales_amount'] = preds\nsample.to_csv('sub.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}